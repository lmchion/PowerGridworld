[H[2J[3Jrunning locally true
iteration set 1
env_set ['001']
env 001
training_iteration 100


OUT ::: 



ERROR ::: 
b"[INFO] train_hs.py:39: ARGS: {'env_name': 'buildings', 'system_load_rescale_factor': 0.6, 'max_episode_steps': 288, 'local_dir': '/home/ec2-user/PowerGridworld/data/outputs/ray_results', 'stop_timesteps': 10000000000, 'stop_iters': 100, 'stop_reward': 0.0, 'run': 'PPO', 'framework': 'torch', 'num_gpus': 1, 'num_cpus': 8, 'num_samples': 1, 'log_level': 'WARN', 'node_ip_address': '127.0.0.1', 'input_dir': '/home/ec2-user/PowerGridworld/data/inputs', 'last_checkpoint': 'None', 'training_iteration': '100', 'scenario_id': '001', 'standalone_train': True}"
b'[INFO] train_hs.py:64: ENV CONFIG'
b'\x1b[2m\x1b[36m(PPO pid=22184)\x1b[0m 2023-04-11 03:42:18,255\tWARNING algorithm_config.py:596 -- Cannot create PPOConfig from given `config_dict`! Property __stdout_file__ not supported.'
b"\x1b[2m\x1b[36m(PPO pid=22184)\x1b[0m 2023-04-11 03:42:18,258\tINFO algorithm.py:506 -- Current log_level is WARN. For more information, set 'log_level': 'INFO' / 'DEBUG' or use the -v and -vv flags."
b'\x1b[2m\x1b[36m(RolloutWorker pid=22643)\x1b[0m /opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22643)\x1b[0m   if not isinstance(terminated, (bool, np.bool8)):'
b"\x1b[2m\x1b[36m(RolloutWorker pid=22642)\x1b[0m 2023-04-11 03:42:22,762\tWARNING env.py:166 -- Your env reset() method appears to take 'seed' or 'return_info' arguments. Note that these are not yet supported in RLlib. Seeding will take place using 'env.seed()' and the info dict will not be returned from reset."
b'\x1b[2m\x1b[36m(RolloutWorker pid=22642)\x1b[0m /opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22642)\x1b[0m   if not isinstance(terminated, (bool, np.bool8)):'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22646)\x1b[0m /opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22646)\x1b[0m   if not isinstance(terminated, (bool, np.bool8)):'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22648)\x1b[0m /opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22648)\x1b[0m   if not isinstance(terminated, (bool, np.bool8)):'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22644)\x1b[0m /opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22644)\x1b[0m   if not isinstance(terminated, (bool, np.bool8)):'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22649)\x1b[0m /opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22649)\x1b[0m   if not isinstance(terminated, (bool, np.bool8)):'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22645)\x1b[0m /opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22645)\x1b[0m   if not isinstance(terminated, (bool, np.bool8)):'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22647)\x1b[0m /opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/gymnasium/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)'
b'\x1b[2m\x1b[36m(RolloutWorker pid=22647)\x1b[0m   if not isinstance(terminated, (bool, np.bool8)):'
b'2023-04-11 03:56:08,238\tERROR trial_runner.py:1062 -- Trial PPO_001_d922f_00000: Error processing event.'
b'ray.exceptions.RayTaskError(ValueError): \x1b[36mray::PPO.train()\x1b[39m (pid=22184, ip=172.31.80.252, repr=PPO)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py", line 88, in loss'
b'    curr_action_dist = dist_class(logits, model)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/models/torch/torch_action_dist.py", line 512, in __init__'
b'    self.flat_child_distributions = tree.map_structure('
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/tree/__init__.py", line 435, in map_structure'
b'    [func(*args) for args in zip(*map(flatten, structures))])'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/tree/__init__.py", line 435, in <listcomp>'
b'    [func(*args) for args in zip(*map(flatten, structures))])'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/models/torch/torch_action_dist.py", line 513, in <lambda>'
b'    lambda dist, input_: dist(input_, model),'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/models/torch/torch_action_dist.py", line 250, in __init__'
b'    self.dist = torch.distributions.normal.Normal(mean, torch.exp(log_std))'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/torch/distributions/normal.py", line 54, in __init__'
b'    super(Normal, self).__init__(batch_shape, validate_args=validate_args)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/torch/distributions/distribution.py", line 55, in __init__'
b'    raise ValueError('
b'ValueError: Expected parameter loc (Tensor of shape (288, 1)) of distribution Normal(loc: torch.Size([288, 1]), scale: torch.Size([288, 1])) to satisfy the constraint Real(), but found invalid values:'
b'tensor([[nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b"        [nan]], device='cuda:0', grad_fn=<SplitBackward0>)"
b''
b'The above exception was the direct cause of the following exception:'
b''
b'\x1b[36mray::PPO.train()\x1b[39m (pid=22184, ip=172.31.80.252, repr=PPO)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 368, in train'
b'    raise skipped from exception_cause(skipped)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 365, in train'
b'    result = self.step()'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 782, in step'
b'    results, train_iter_ctx = self._run_one_training_iteration()'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2713, in _run_one_training_iteration'
b'    results = self.training_step()'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo.py", line 373, in training_step'
b'    train_results = multi_gpu_train_one_step(self, train_batch)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/execution/train_ops.py", line 163, in multi_gpu_train_one_step'
b'    results = policy.learn_on_loaded_batch('
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/policy/torch_policy_v2.py", line 771, in learn_on_loaded_batch'
b'    tower_outputs = self._multi_gpu_parallel_grad_calc(device_batches)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/policy/torch_policy_v2.py", line 1259, in _multi_gpu_parallel_grad_calc'
b'    raise last_result[0] from last_result[1]'
b'ValueError: Expected parameter loc (Tensor of shape (288, 1)) of distribution Normal(loc: torch.Size([288, 1]), scale: torch.Size([288, 1])) to satisfy the constraint Real(), but found invalid values:'
b'tensor([[nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b"        [nan]], device='cuda:0', grad_fn=<SplitBackward0>)"
b' tracebackTraceback (most recent call last):'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/policy/torch_policy_v2.py", line 1174, in _worker'
b'    self.loss(model, self.dist_class, sample_batch)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/algorithms/ppo/ppo_torch_policy.py", line 88, in loss'
b'    curr_action_dist = dist_class(logits, model)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/models/torch/torch_action_dist.py", line 512, in __init__'
b'    self.flat_child_distributions = tree.map_structure('
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/tree/__init__.py", line 435, in map_structure'
b'    [func(*args) for args in zip(*map(flatten, structures))])'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/tree/__init__.py", line 435, in <listcomp>'
b'    [func(*args) for args in zip(*map(flatten, structures))])'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/models/torch/torch_action_dist.py", line 513, in <lambda>'
b'    lambda dist, input_: dist(input_, model),'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/rllib/models/torch/torch_action_dist.py", line 250, in __init__'
b'    self.dist = torch.distributions.normal.Normal(mean, torch.exp(log_std))'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/torch/distributions/normal.py", line 54, in __init__'
b'    super(Normal, self).__init__(batch_shape, validate_args=validate_args)'
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/torch/distributions/distribution.py", line 55, in __init__'
b'    raise ValueError('
b'ValueError: Expected parameter loc (Tensor of shape (288, 1)) of distribution Normal(loc: torch.Size([288, 1]), scale: torch.Size([288, 1])) to satisfy the constraint Real(), but found invalid values:'
b'tensor([[nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b'        [nan],'
b"        [nan]], device='cuda:0', grad_fn=<SplitBackward0>)"
b''
b'In tower 0 on device cuda:0'
b'Traceback (most recent call last):'
b'  File "/home/ec2-user/PowerGridworld/examples/marl/rllib/heterogeneous/train_hs.py", line 217, in <module>'
b'    last_check = main(**vars(args))'
b'  File "/home/ec2-user/PowerGridworld/examples/marl/rllib/heterogeneous/train_hs.py", line 143, in main'
b'    experiment = tune.run('
b'  File "/opt/conda/envs/gridworld_hs/lib/python3.10/site-packages/ray/tune/tune.py", line 792, in run'
b'    raise TuneError("Trials did not complete", incomplete_trials)'
b"ray.tune.error.TuneError: ('Trials did not complete', [PPO_001_d922f_00000])"
Finished 001 process in 862.4642729759216 seconds.
Traceback (most recent call last):
  File "/home/ec2-user/PowerGridworld/examples/marl/rllib/heterogeneous/train_loop_hs.py", line 102, in <module>
    _ = main(**vars(args))
  File "/home/ec2-user/PowerGridworld/examples/marl/rllib/heterogeneous/train_loop_hs.py", line 78, in main
    run_date=run_date.group(1)
AttributeError: 'NoneType' object has no attribute 'group'
